{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition: Tennis\n",
    "\n",
    "---\n",
    "\n",
    "This notebook trains two DDPG agents collaboratively playing tennis.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from collections import deque\n",
    "from agent import Agent\n",
    "import workspace_utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two agents\n",
    "agent1 = Agent(state_size=state_size, action_size=action_size, random_seed=0)\n",
    "agent2 = Agent(state_size=state_size, action_size=action_size, random_seed=0)\n",
    "agents = [agent1, agent2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDPG implementation based on Udacity's bipedal code\n",
    "def ddpg(n_episodes=4096, goal=0.5, print_every=100):\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    t_sum = 0 \n",
    "    \n",
    "    for i_episode in range(n_episodes):\n",
    "        t_0 = time.time()\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent1.reset()\n",
    "        agent2.reset()\n",
    "        scores_episode = np.zeros(num_agents)\n",
    "        steps = 0\n",
    "        \n",
    "        while True:\n",
    "            action1 = agent1.act(states[0])            \n",
    "            action2 = agent2.act(states[1]) \n",
    "            actions = [action1, action2]\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards                         \n",
    "            dones = env_info.local_done                       \n",
    "            \n",
    "            agent1.step(states[0], actions[0], rewards[0], next_states[0], dones[0])\n",
    "            agent2.step(states[0], actions[0], rewards[0], next_states[0], dones[0])\n",
    "            \n",
    "            states = next_states\n",
    "            scores_episode += rewards\n",
    "            steps += 1\n",
    "            if np.any(dones):                               \n",
    "                break\n",
    "                \n",
    "        score = np.max(scores_episode)\n",
    "        scores.append(score)\n",
    "        scores_window.append(score)\n",
    "        avg = np.mean(scores_window)            \n",
    "        t_delta = time.time() - t_0\n",
    "        t_sum += t_delta \n",
    "        if i_episode % print_every == 0:\n",
    "            print('Episode: {}\\tScore: {:.2f}\\tAvg: {:.2f}\\tTook: {:.2f}sec\\tTotal: {:.2f}min\\tSteps: {}'.format(i_episode, score, avg, t_delta, t_sum/60, steps))\n",
    "        if avg > goal:\n",
    "            print(\"\\n\\nSolved in {} episodes with {:.2f} avg score after {:.2f}min.\".format(i_episode, avg, t_sum/60))\n",
    "            torch.save(agent1.actor_local.state_dict(), 'checkpoint_actor1.pth')\n",
    "            torch.save(agent1.critic_local.state_dict(), 'checkpoint_critic1.pth')\n",
    "            torch.save(agent2.actor_local.state_dict(), 'checkpoint_actor2.pth')\n",
    "            torch.save(agent2.critic_local.state_dict(), 'checkpoint_critic2.pth')\n",
    "            break\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\tScore: 0.00\tAvg: 0.00\tTook: 0.13sec\tTotal: 0.00min\tSteps: 15\n",
      "Episode: 100\tScore: 0.00\tAvg: 0.00\tTook: 0.41sec\tTotal: 0.62min\tSteps: 15\n",
      "Episode: 200\tScore: 0.00\tAvg: 0.01\tTook: 0.42sec\tTotal: 1.33min\tSteps: 14\n",
      "Episode: 300\tScore: 0.00\tAvg: 0.01\tTook: 0.39sec\tTotal: 2.04min\tSteps: 14\n",
      "Episode: 400\tScore: 0.00\tAvg: 0.00\tTook: 0.37sec\tTotal: 2.70min\tSteps: 14\n",
      "Episode: 500\tScore: 0.00\tAvg: 0.00\tTook: 0.37sec\tTotal: 3.36min\tSteps: 14\n",
      "Episode: 600\tScore: 0.00\tAvg: 0.00\tTook: 0.40sec\tTotal: 4.02min\tSteps: 15\n",
      "Episode: 700\tScore: 0.10\tAvg: 0.02\tTook: 0.83sec\tTotal: 4.86min\tSteps: 31\n",
      "Episode: 800\tScore: 0.00\tAvg: 0.02\tTook: 0.38sec\tTotal: 5.65min\tSteps: 14\n",
      "Episode: 900\tScore: 0.00\tAvg: 0.00\tTook: 0.37sec\tTotal: 6.32min\tSteps: 14\n",
      "Episode: 1000\tScore: 0.00\tAvg: 0.04\tTook: 0.85sec\tTotal: 7.32min\tSteps: 32\n",
      "Episode: 1100\tScore: 0.00\tAvg: 0.04\tTook: 0.38sec\tTotal: 8.31min\tSteps: 14\n",
      "Episode: 1200\tScore: 0.00\tAvg: 0.03\tTook: 0.34sec\tTotal: 9.15min\tSteps: 13\n",
      "Episode: 1300\tScore: 0.00\tAvg: 0.07\tTook: 0.37sec\tTotal: 10.35min\tSteps: 14\n",
      "Episode: 1400\tScore: 0.10\tAvg: 0.07\tTook: 0.80sec\tTotal: 11.63min\tSteps: 30\n",
      "Episode: 1500\tScore: 0.10\tAvg: 0.10\tTook: 0.89sec\tTotal: 13.12min\tSteps: 31\n",
      "Episode: 1600\tScore: 0.10\tAvg: 0.09\tTook: 0.86sec\tTotal: 14.54min\tSteps: 31\n",
      "Episode: 1700\tScore: 0.10\tAvg: 0.11\tTook: 0.83sec\tTotal: 16.24min\tSteps: 30\n",
      "Episode: 1800\tScore: 0.10\tAvg: 0.11\tTook: 0.89sec\tTotal: 18.00min\tSteps: 31\n",
      "Episode: 1900\tScore: 0.10\tAvg: 0.19\tTook: 1.39sec\tTotal: 21.47min\tSteps: 52\n",
      "Episode: 2000\tScore: 0.10\tAvg: 0.36\tTook: 1.44sec\tTotal: 27.92min\tSteps: 52\n",
      "\n",
      "\n",
      "Solved in 2085 episodes with 0.51 avg score after 35.96min.\n"
     ]
    }
   ],
   "source": [
    "# Starts the training\n",
    "from workspace_utils import active_session\n",
    " \n",
    "with active_session():\n",
    "    scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c0366be10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('#Episode')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
